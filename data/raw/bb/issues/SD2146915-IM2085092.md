# mno - BigStreamer - SD2146915-IM2085092 [DR][IBANK] Application : IBank_Ingestion MergeBatch Failed

<b>Description:</b>

```
We have the following alert msg on Grafana.
[DR][IBANK] IBank_Ingestion MergeBatch Failed
```

<b>Actions Taken:</b>

1. Login to `dr1edge01` with your acount
```
su - PRODREST
```

2. We check the script log:

Script Logs: `/var/log/ingestion/PRODREST/ibank/log/cronExecutor_ibankBatch_full.log`

Error code: `Log messages was for memory fault.`

We also look at the Spark logs:

Use Firefox on dr1edge01.mno.gr/pr1edge01.mno.gr to access the logs via YARN Resource Manager UI

Script: `/opt/ingestion/PRODREST/common/scripts/cronExecutor_MergeBatchWithLock_hdfs_STABLE.sh` on dr1edge01.mno.gr/pr1edge01.mno.gr (each   edge server submits to a different cluster)

  **Troubleshooting Steps**:

- Use the script logs `/var/log/ingestion/PRODREST/ibank/log/cronExecutor_ibankBatch_full.log` to identify the cause of the failure

If we have mentioned `error code` then :
```bash
vi /opt/ingestion/PRODREST/online/spark/submit/submitmnoSparkTopology_batch_cluster_mno_STABLE.sh
```

Change `colaesce` from `6` to `12` and save changes. 

>Ndef: Inform the next day developers in order to update the git repo with the new value

- Ensure that no records are present in prod_trlog_ibank.service_audit_old

``` bash
  # eg. 09-11-2019
  impala-shell -k --ssl -i ${HOSTNAME/01/} -q "select  count(*) from prod_trlog_ibank.service_audit where par_dt='20191109';"
```

- If no records exist and no other process is up, you can ran the script again.
  - For the previous day:

    ``` bash
    /opt/ingestion/PRODREST/historical/ibank_service_audit_insert_join_distinct.sh `date -d '-1 day' '+%Y%m%d'` >> /var/log/ingestion/PRODREST/ibank/log/ibank_service_audit_insert_join_distinct.log 2>&1
    ```

  - For a specified date:

    ``` bash
    # e.g. 09-11-2019
    /opt/ingestion/PRODREST/historical/ibank_service_audit_insert_join_distinct.sh 20191109 >> /var/log/ingestion/PRODREST/ibank/log/ibank_service_audit_insert_join_distinct.log 2>&1

The process runs for well over an hour under normal circumstances or even longer for heavy load. Use of screen command advised.

After the above script completed we ran the next sub-steps manually:

1. `Distinct join to Service Audit` from [here](https://metis.ghi.com/obss/oss/sysadmin-group/support/-/blob/master/KnowledgeBase/mno/BigStreamer/supportDocuments/applicationFlows/ibank.md#distinct-join-to-service-audit)
2.  `Report stats to Graphite` from [here](https://metis.ghi.com/obss/oss/sysadmin-group/support/-/blob/master/KnowledgeBase/mno/BigStreamer/supportDocuments/applicationFlows/ibank.md#report-stats-to-graphite)
3. `Drop hourly partitions` from [here](https://metis.ghi.com/obss/oss/sysadmin-group/support/-/blob/master/KnowledgeBase/mno/BigStreamer/supportDocuments/applicationFlows/ibank.md#drop-hourly-partitions)
4. `Upsert to HBase (Migration)` from [here](https://metis.ghi.com/obss/oss/sysadmin-group/support/-/blob/master/KnowledgeBase/mno/BigStreamer/supportDocuments/applicationFlows/ibank.md#upsert-to-hbase-migration)
5. `Send reports to business users` from [here](https://metis.ghi.com/obss/oss/sysadmin-group/support/-/blob/master/KnowledgeBase/mno/BigStreamer/supportDocuments/applicationFlows/ibank.md#send-reports-to-business-users)
6. `Duplicates between Impala and Kudu/HBase` from [here](https://metis.ghi.com/obss/oss/sysadmin-group/support/-/blob/master/KnowledgeBase/mno/BigStreamer/supportDocuments/applicationFlows/ibank.md#duplicates-between-impala-and-kuduhbase)



