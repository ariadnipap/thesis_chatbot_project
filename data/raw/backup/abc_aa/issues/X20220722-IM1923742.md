# abc - IM1923742 - Job's problem

<b>Description:</b>

```
Good morning,
it has been observed that jobs show the problem Engine exited with status 34.
some of them are:
• Set_Point_Automation job in the Set Point Automation project (error today 22/7)
• Cabins Live Measurements job in the Energy Bills project (error yesterday 21/7)
• Flows_update_all_counters_12:00_no_par_dt job in the Monitoring Flows project (error yesterday 7/15)
```

<b>Actions Taken:</b>

1. Connect with you personal ldap account in 'https://mncdsw1.bigdata.abc.gr/'
2. Go to last tab(admin).
3. Select `Activity` tab.
4. Inspect the Jobs in question.

The jobs are in `FAILED` status. The logs for the failed applications are missing.
 
5. Troubleshoot from the command line:

From `mncdsw1` as root (use personal account and then sudo):

```bash
kubectl get pods -w -A # Wait a pod to fail (namespace should be like default-user-XXX)

# After a while, a pod has failed, describe it

kubectl describe pod -n default-user-XXX XXXXXXXX
```

``` logs
Events
Warning  FailedCreatePodSandBox  10s                    kubelet, wrkcdsw4.bigdata.abc.gr  Failed to create pod sandbox: rpc error: code = Unknown desc = [failed to set up sandbox container "..." network for pod "XXXXXXXX": networkPlugin cni failed to set up pod "XXXXXXXX_default" network: unable to allocate IP address: Post http://127.0.0.1:6784/ip/....: dial tcp 127.0.0.1:6784: connect: connection refused, failed to clean up sandbox container "...." network for pod "XXXXXXXX": networkPlugin cni failed to teardown pod "XXXXXXXX_default" network: Delete http://127.0.0.1:6784/ip/....: dial tcp 127.0.0.1:6784: connect: connection refused]
```

This error points us to the CNI plugin

Check the logs for the weave pods

``` bash
kubectl logs -n kube-system weave-net-XXXXX
# Weave pod in wrkcdsw4 has stopped logging events
```

The pod was not responding and could not be deleted.

7. Restart the docker daemon to restart all containers on `wrkcdsw4`

_At the time of the issue, CDSW had stale configuration that required full restart (outage) which was not desirable_

To avoid applying the settings, restart the service with the same configuration by triggering a restart by `supervisord` deployed as part of the Cloudera agent

<details> ![Danger ahead](https://media3.giphy.com/media/vvzMdSygQejBIejeRO/200w.gif?cid=6c09b952aacsm9yssw6k6q0z5v8ejuy82rjpvw6qdhglcwpu&rid=200w.gif&ct=g) </details>

From wrkcdsw4 as root (use personal account and then sudo):

``` bash
/opt/cloudera/cm-agent/bin/supervisorctl -c /var/run/cloudera-scm-agent/supervisor/supervisord.conf status | grep DOCKER
# Sample
# 145071-cdsw-CDSW_DOCKER          RUNNING   pid 39353, uptime 29 days, 0:40:20
/opt/cloudera/cm-agent/bin/supervisorctl -c /var/run/cloudera-scm-agent/supervisor/supervisord.conf restart 145071-cdsw-CDSW_DOCKER
```

8. Check that the node is operational after the restart

From `mncdsw1` as root (use personal account and then sudo):

```bash
cdsw status # You might have to wait a few minutes
```

9. Inform the customer about the problem

``` text
A component of CDSW on worker node 4 encountered a problem resulting in jobs running on that node not being able to start. The function of the component has been restored and the jobs are now running normally.

Please let us know if you need anything else or if we can proceed to close the ticket.
```

<b>Affected Systems:</b>

abc Bigstreamer CDSW

<b>Action Points:</b>

