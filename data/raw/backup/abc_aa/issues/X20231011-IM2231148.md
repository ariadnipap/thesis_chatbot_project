## Subject: pod failure at RAN.AI

Ticket Number: IM2231148

Priority: High

Date: 10-11-2023

<b>Description:</b>
```
Good morning,

We saw that the airflow scheduler is down due to access rights in the logs folder.
pod airflow-scheduler-0 had entered a restart loop as shown below.

root@kubemaster1:~# kubectl get pods -n ranai-geo
NAME READY STATUS RESTARTS AGE
airflow-postgresql-0 1/1 Running 0 326d
airflow-scheduler-0 0/2 CrashLoopBackOff 970 (68s ago) 187d
airflow-statsd-85d5d8768b-hgzzc 1/1 Running 0 326d
airflow-webserver-6c8448476d-hs4nb 1/1 Running 0 187d
Το έκανα restart αλλά είναι σε status Init:0/1 πλέον. Επισυνάπτω logs και τα events μετά το restart του pod.
root@kubemaster1:~# kubectl get pods -n ranai-geo
NAME READY STATUS RESTARTS AGE
airflow-postgresql-0 1/1 Running 0 326d
airflow-scheduler-0 0/2 Init:0/1 0 67s
airflow-statsd-85d5d8768b-hgzzc 1/1 Running 0 326d
airflow-webserver-6c8448476d-hs4nb 1/1 Running 0 187d
abc-prod-ranai-geo-be-f7f8fc5c4-rv66z 1/1 Running 0 25h
abc-prod-ranai-geo-clustering-68975fb5b5-qvztf 1/1 Running 0 25h
abc-prod-ranai-geo-fe-9c5c7bc7c-72fpn 1/1 Running 0 141d
abc-prod-ranai-geo-postgres-0 1/1 Running 0 165d
root@kubemaster1:~# kubectl get events -n ranai-geo
LAST SEEN TYPE REASON OBJECT MESSAGE
25m Warning BackOff pod/airflow-scheduler-0 Back-off restarting failed container
35m Warning Unhealthy pod/airflow-scheduler-0 Liveness probe failed: Unable to load the config, contains a configuration error....
21m Normal Scheduled pod/airflow-scheduler-0 Successfully assigned ranai-geo/airflow-scheduler-0 to kubeworker1.bigdata.abc.gr
13m Warning FailedMount pod/airflow-scheduler-0 Unable to attach or mount volumes: unmounted volumes=[logs], unattached volumes=[kerberos-keytab connectors-config jssecacerts kube-api-access-2df5h config logs]: timed out waiting for the condition
19m Warning FailedMount pod/airflow-scheduler-0 MountVolume.MountDevice failed for volume "pvc-c826d577-e764-470e-9904-3986042810aa" : rpc error: code = DeadlineExceeded desc = context deadline exceeded
8m59s Warning FailedMount pod/airflow-scheduler-0 MountVolume.MountDevice failed for volume "pvc-c826d577-e764-470e-9904-3986042810aa" : rpc error: code = Internal desc = format of disk "/dev/longhorn/pvc-c826d577-e764-470e-9904-3986042810aa" failed: type:("ext4") target:("/var/lib/kubelet/plugins/kubernetes.io/csi/pv/pvc-c826d577-e764-470e-9904-3986042810aa/globalmount") options:("defaults") errcode:(exit status 1) output:(mke2fs 1.45.5 (07-Jan-2020)...
9m26s Warning FailedMount pod/airflow-scheduler-0 Unable to attach or mount volumes: unmounted volumes=[logs], unattached volumes=[kube-api-access-2df5h config logs kerberos-keytab connectors-config jssecacerts]: timed out waiting for the condition
15m Warning FailedMount pod/airflow-scheduler-0 Unable to attach or mount volumes: unmounted volumes=[logs], unattached volumes=[connectors-config jssecacerts kube-api-access-2df5h config logs kerberos-keytab]: timed out waiting for the condition
9m24s Normal Scheduled pod/airflow-scheduler-0 Successfully assigned ranai-geo/airflow-scheduler-0 to kubeworker1.bigdata.abc.gr
32s Warning FailedMount pod/airflow-scheduler-0 Unable to attach or mount volumes: unmounted volumes=[logs], unattached volumes=[connectors-config jssecacerts kube-api-access-nrb25 config logs kerberos-keytab]: timed out waiting for the condition
2m58s Warning FailedMount pod/airflow-scheduler-0 MountVolume.MountDevice failed for volume "pvc-c826d577-e764-470e-9904-3986042810aa" : rpc error: code = Internal desc = format of disk "/dev/longhorn/pvc-c826d577-e764-470e-9904-3986042810aa" failed: type:("ext4") target:("/var/lib/kubelet/plugins/kubernetes.io/csi/pv/pvc-c826d577-e764-470e-9904-3986042810aa/globalmount") options:("defaults") errcode:(exit status 1) output:(mke2fs 1.45.5 (07-Jan-2020)...
5m4s Warning FailedMount pod/airflow-scheduler-0 Unable to attach or mount volumes: unmounted volumes=[logs], unattached volumes=[jssecacerts kube-api-access-nrb25 config logs kerberos-keytab connectors-config]: timed out waiting for the condition
2m47s Warning FailedMount pod/airflow-scheduler-0 Unable to attach or mount volumes: unmounted volumes=[logs], unattached volumes=[kerberos-keytab connectors-config jssecacerts kube-api-access-nrb25 config logs]: timed out waiting for the condition
9m24s Normal SuccessfulCreate statefulset/airflow-scheduler create Pod airflow-scheduler-0 in StatefulSet airflow-scheduler successful

Please for your checks.
Thanks
```

<b>Investigation:</b>

Pod Initialization: The initial issue was identified as the airflow-scheduler pod getting stuck during initialization.

cmd: `kubectl describe <airflow-scheduler-pod> -n ranai-geo`

![error_mount](.media/mounterror.JPG)

Configmap Mounting Issues: Further examination of the pod's logs and configuration revealed that some required configmaps were failing to mount correctly, causing a disruption in the pod initialization process.

Identify the airflow pv

![pv](.media/getpv.JPG)

`kubectl logs instance-manager-r-28535c55 -n instance-manager-r`

PVC logs

![pvclogs1](.media/pvc1logs.JPG)
![pvclogs2](.media/pvc2logs.JPG)
![pvclogs3](.media/pv3logs.JPG)

Longhorn Investigation: To investigate possible underlying storage issues, we accessed [Longhorn](https://kubemaster-vip.bigdata.abc.gr/longhorn/) and discovered that the PVC (Persistent Volume Claim) associated with the airflow-scheduler had three replicatas of airflow-scheduler pvc stuck in a deleting state.

![longhornUI](.media/longhornbug.JPG)

<b>Resolution:</b>
To resolve the issue and restore the airflow-scheduler pod's functionality, the following steps were taken:

Deletion of Problematic PVC: The three problematic replicas of airflow-scheduler PVC in Longhorn, which were stuck in a deleting state, were the problem, as a result we deleted the airflow's PVC.
Nfgh: It is important to mention that this issue might be related to a bug within the Longhorn storage system, as it caused replicated PVCs to get stuck in a deleting state. Further investigation and monitoring of Longhorn may be necessary to prevent such issues from recurring. Also see this [thread](https://github.com/longhorn/longhorn/issues/4278)

<b>Actions Taken:</b>

Deleted problematic PVCs in Longhorn under instance-manager-r namespace.
`kubectl delete pvc pvc-c826d577-e764-470e-9904-3986042810aa -n ranai-geo`

<b>Recommendations:</b>

Monitor Longhorn for any recurring issues with PVC management to prevent similar incidents. 

Ticket Status:
Resolved successfully
