# abc - IM1443515 - radius.radacct_hist

<b>Description:</b>

```
Good morning,

Please investigate the three-day reduction in registrations at 06:00 and 07:00 (02/08 - 02/10) and inform us about it.
```

<b>Actions Taken:</b>
- Login to `un2.bigdata.abc.gr` with personal account and change to `intra` with sudo.
- Compare the count of the inserted data between the radius.radacct_hist and the original files radius.radacct_orig_files

```bash
[intra@un2 ~]$ secimp
[un-vip.bigdata.abc.gr:22222] > select par_dt,substr(acctupdatetime,1,13),count(*) from radius.radacct_hist where par_dt>'20210209' group by 1,2 order by 1,2;
| 20210209 | 2021-02-09 06 | 597 |
| 20210209 | 2021-02-09 07 | 697082 |

[un-vip.bigdata.abc.gr:22222] > select substr(acctupdatetime,1,13),count(*) from radius.radacct_orig_files where acctupdatetime>'2021-02-09' group by 1 order by 1;
| 2021-02-09 06                 | 1430757  |
| 2021-02-09 07                 | 1393639  |
```
So, the files had been correctly ingested but the radacct_hist table has a problem.

- Compare the total ingested lines with the total inserted lines for the provided dates/hours (the provided hours are in UTC time - Impala)

```bash
[intra@un2 ~]$ for i in {08..09};do grep -E "2021/02/09 ${i}.*Total lines" /shared/abc/radius/DataParser/scripts/log/radius_cron.log;done
[2021/02/09 08:12:01] - info - Total lines :  <2130925>
[2021/02/09 09:12:37] - info - Total lines :  <2136145>

[intra@un2 ~]$ for i in {08..09};do grep -B 5 Modified /shared/abc/radius/log/000_radius_ops.20210209.log | grep -A 6 "insert into radius.radacct_hist" | grep -C 3 "Query submitted at: 2021-02-09 ${i}" | grep Modified;done
Modified 0 row(s) in 0.58s
Modified 2136145 row(s) in 12.15s
```

As you can see, the data had been correctly inserted into radius.radacct_load (2130925) but the insert into the radius.radacct_hist had insert 0 rows @  09/02/2021 08:18:15.

Do the same process for 08/02/2021 and 10/02/2021 and observe the same outcome.

- The ingested files have been backed up in the radius.radacct_orig_files. Find the appropriate files for the given dates/hours

```bash
[intra@un2 ~]$ for i in {08..10};do hdfs dfs -ls /ez/warehouse/radius.db/radacct_orig_files/ | grep 202102${i}_08;done
-rwxrwx--x+  3 hive hive  839787710 2021-02-08 08:11 /ez/warehouse/radius.db/radacct_orig_files/RAD___radacct_2021-02-08_07-30.csv.20210208_081002.utc
-rwxrwx--x+  3 hive hive  844035825 2021-02-09 08:12 /ez/warehouse/radius.db/radacct_orig_files/RAD___radacct_2021-02-09_07-30.csv.20210209_081002.utc
-rwxrwx--x+  3 hive hive  844035825 2021-02-09 08:12 /ez/warehouse/radius.db/radacct_orig_files/RAD___radacct_2021-02-10_07-30.csv.20210210_081001.utc
```

- Copy the files to the load table

```bash
[intra@un2 ~]$ hdfs dfs -cp /ez/warehouse/radius.db/radacct_orig_files/RAD___radacct_2021-02-08_07-30.csv.20210208_081002.utc /ez/warehouse/radius.db/radacct_load/
```

Do the same for the other two files.

- Run the radius procedure again

```bash
[intra@un2 ~] /shared/abc/radius/bin/000_radius_ops.sh >> /shared/abc/radius/log/000_radius_ops.20210211.log.manual 2>&1
```
<b>Affected Systems:</b>

abc Bigstreamer

<b>Action Points:</b>

Resolution of Cloudera Issue 752877 - Hive Metastore innodb lock await time out which is the root cause of this issue.
