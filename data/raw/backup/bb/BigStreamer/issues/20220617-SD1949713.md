# mno - BigStreamer - SD1949713 - Πρόβλημα στα services του dr cluster

<b>Description:</b>

```
Good evening,

We received 120 emails from the DR cluster services saying they have a problem and when we entered the cloudera manager everything was red. It seems that some of our applications crashed as well. Can you tell us what happened?

Best regards,
Thanos Papakostas
```

<b>Actions Taken:</b>

1. Login to grafana to make sure that the alert is about DR SITE. We noticed that there were alerts for IBANK Spark Waiting Batches but not for Visible which predisposes us for an issue with Kudu.
![ibank_kudu_problem](.media/SD1949713/ibank_kudu_problem.PNG)
2. Login to Cloudera UI for the DR Site.
3. From `Charts>Impala Perf` we noticed increased resource commitment through Impala Pool Reserved and Threads charts.
![Impala Pool Reserved](.media/Impala_pool_reserved.PNG)
![Threads](.media/threads.PNG)
4. From `Cloudera Manager>Impala>Queries` we searched for queries that took place at the time the problem raised. We found that the query with ID 6d44d9525a681fb8:5e536ffc00000000 had Threads:CPU Time 10.7h. Upon inspection through `Query Details` we saw that the query was of high complexity with conversions and comparisons with regex.
![Query](.media/query.PNG)
5. Through Cloudera logs, we noticed that the query impacted the services in the form of timeouts for Kudu and Hive due to slow communication with Sentry Service.
![hive_problem](.media/SD1949713/hive_problem.PNG)
![timeouts_kudu](.media/SD1949713/timeouts_kudu.PNG)
![sentry_problem](.media/SD1949713/sentry_problem.PNG)
6. The problem was resolved without any interference from our side. We informed the client that it was due to a high complexity query ran by a normal user that resulted in an increased undertaking of resources.

<b>Affected Systems:</b>

DR Site
