# mno - BigStreamer - IM1317401 - [PR][IBANK] Ροές Data warehouse

<b>Description:</b>

```
It seems that the Data Warehouse jobs have not run, can you see this?

select * from prod_trlog_ibank.monitor_sched_jobs where par_dt=20210429

IBank_Migration Historical JOB 20210429 SUCCESS 2021-04-30 02:00:01.000 2021-04-30 02:03:50.000 dr1edge01.mno.gr
2 IBank_Migration Historical Sqoop_Import 20210429 SUCCESS 2021-04-30 02:00:01.000 2021-04-30 02:01:51.000 dr1edge01.mno.gr
3 IBank_Migration Historical Impala_Insert 20210429 SUCCESS 2021-04-30 02:03:07.000 2021-04-30 02:03:50.000 dr1edge01.mno.gr
4 IBank_Migration Historical to SA Impala_Insert 20210429 SUCCESS 2021-04-30 02:04:23.000 2021-04-30 02:06:21.000 dr1edge01.mno.gr
5 IBank_Migration Historical to SA JOB 20210429 SUCCESS 2021-04-30 02:04:23.000 2021-04-30 02:06:21.000 dr1edge01.mno.gr
6 IBank_Ingestion MergeBatch JOB 20210429 FAILED 2021-04-30 09:37:35.000 2021-04-30 09:37:35.000 dr1edge.mno.gr

We also see that the merge batch has also crashed.

```

<b>Actions Taken:</b>

1. Login to `https://dr1edge01.mno.gr:3000` with personal account
2. Inspected `[PR][IBANK] Overview` graph
3. Merge Batch job has FAILED
4. MergeBatch job was not running : "yarn application -list | grep -i merge | grep -v Hourly"
5. Yarn/Spark logs examined, foun that job was failed due to lack of RAM caused by large amount of Data
6. MergeBatch job resubmited but failed again.
7. Vi /opt/ingestion/PRODREST/ibank/spark/submit/submitmnoSparkTopology_batch_cluster_mno_STABLE.sh
8. Search for “coalesce” , Change/replace “-coalesce=$NUMBER_OF_EXECUTORS \ “ , To : “-coalesce=96 \ “
9. Search for "--spark.sql.shuffle.partitions=16  \"  to : "--spark.sql.shuffle.partitions=96  \" 
10. As PRODREST user, re-run the /opt/ingestion/PRODREST/historical/ibank_histMigrate_aggr_MergeBatchWithLock_STABLE_v2.sh cron script from the MERGE section onwards.

<b>Affected Systems:</b>

DR Site IBANK 

<b>Action Points:</b>
