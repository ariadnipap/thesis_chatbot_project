---
title: Location Mobility Export Failure Due to Memory Exhaustion and Missing HDFS File
description: The Location Mobility LM_02_LTE file failed to export due to memory exhaustion on sn102 caused by a heavy user query, followed by missing HDFS files triggering I/O errors on other nodes. Issue was resolved via retention cleanup and table refresh, without flow restarts.
tags:
  - bigstreamer
  - location mobility
  - lm_02_lte
  - sn102
  - impala
  - memory exhaustion
  - out of memory
  - disk io error
  - missing hdfs file
  - ranai-geo
  - npce.eea_hour
  - impala daemon
  - export failure
  - trustcenter
  - hdfs
  - retention
  - refresh table
  - root cause analysis
  - lte
last_updated: 2025-05-01
author: ilpap
context:
  issue_id: IM2131290
  system: abc BigStreamer TrustCenter LTE
  failed_flow: Location Mobility LM_02_LTE export
  node_with_issue: sn102.bigdata.abc.gr
  primary_error: Out-of-memory error caused by impala query from ranai-geo
  secondary_error: Disk I/O error due to missing HDFS file on sn111
  recovery_method: Automatic retention and table refresh; dev config correction
  impala_query_user: ranai-geo
  tables_involved:
    - npce.eea_hour
    - refdata.mediation_loc_mobility_load_info
---
# abc - BigStreamer - IM2131290 - Location Mobility LM_02_LTE Export Failure
## Description
The LM_02_LTE export from the Location Mobility workflow failed starting April 19 at 15:00. Below is the initial user-reported issue:
As of yesterday noon at 15:00 the creation of the LM_02_LTE file of the location mobility stream fails. From the HUE jobs you can see that the workflow (export_Location_Mobility_files_to_mediat...) is killed.
We also saw from the logs (lm_export_lte_v2_mon.cron.20230419.log) that at 15:00 when the problem starts we have the following error:
Query submitted at: 2023-04-19 15:00:31 (Coordinator: http://sn72.bigdata.abc.gr:25000)
Query progress can be monitored at: http://sn72.bigdata.abc.gr:25000/query_plan?query_id=c74df6d614d535ea:4de432ac00000000
ERROR: Failed due to unreachable impalad(s): sn102.bigdata.abc.gr:22000
Could not execute command: SELECT
achievable_thr_bytes_down_1,
achievable_thr_bytes_up_1,
achievable_thr_time_down_1,
..................................................................
[2023/04/19 15:19:13] - ERROR: Impala shell command for par_msisdn= failed.
[2023/04/19 15:19:13] - ERROR: Clean up and exit.
% Total % Received % Xferd Average Speed Time Time Time Current
From there onwards we observe errors of the form:
Query submitted at: 2023-04-19 17:00:31 (Coordinator: http://sn64.bigdata.abc.gr:25000)
Query progress can be monitored at: http://sn64.bigdata.abc.gr:25000/query_plan?query_id=094fdeda997b8d44:5826172200000000
ERROR: Disk I/O error on sn62.bigdata.abc.gr:22000: Failed to open HDFS file hdfs://nameservice1/ez/warehouse/npce.db/eea_hour/pardt=2023041910/ef4d08b3073e8531-d909e37b0000010
e_1525512597_data.0.txt
Error(2): No such file or directory
Root cause: RemfghException: File does not exist: /ez/warehouse/npce.db/eea_hour/pardt=2023041910/ef4d08b3073e8531-d909e37b0000010e_1525512597_data.0.txt
at org.apache.hadoop.hdfs.server.namenode.INodeFile.valueOf(INodeFile.java:85)
at org.apache.hadoop.hdfs.server.namenode.INodeFile.valueOf(INodeFile.java:75)
at org.apache.hadoop.hdfs.server.namenode.FSDirStatAndListingOp.getBlockLocations(FSDirStatAndListingOp.java:152)
at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1909)
at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getBlockLocations(NameNodeRpcServer.java:736)
at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getBlockLocations(ClientNamenodeProtocolServerSideTranslatorPB.java:415)
at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:869)
We have similar errors in today's log file lm_export_lte_v2_mon.cron.20230420.log
## Root Cause Analysis
First thing that we have checked were the comments on the [md](https://metis.xyztel.com/obss/oss/sysadmin-group/support/-/blob/master/KnowledgeBase/abc/BigStreamer/supportDocuments/applicationFlows/trustcenter_flows.md) that exists for this flow.
After checking the logs of the flow we saw that the flow was running successfully after it had failed for half day. The reason that it was able to run  was the retention that had already taken place the day that we received the ticket.
We were able to identify the issue that caused the problem. After checking the logs of the host we saw that the host didn't have enough memory at the time.
![sn102_memory](.media/sn102_memory.JPG) because of the user `ranai-geo` that had run an impala query 
![query](.media/query.JPG) that took all the resources of the impala deamon on sn102.
![query_details](.media/q_details.JPG) 
## Actions Taken
No restart needed of the flow. There were some adjustments from dev team that took place.
### Development Intervention
```
It was necessary to make some corrections in the configuration table of the refdata.mediation_loc_mobility_load_info flow to synchronize the data sets that will be exported.
Additionally, due to the following exception a refresh table was added before the select in npce.eea_hour.
ERROR: Disk I/O error on sn111.bigdata.abc.gr:22000: Failed to open HDFS file hdfs://nameservice1/ez/warehouse/npce.db/eea_hour/pardt=2023041912/6547744514f77d2d-0dbb27f700000123_1150579282_data.0.txt
Error(2): No such file or directory
Root cause: RemfghException: File does not exist: /ez/warehouse/npce.db/eea_hour/pardt=2023041912/6547744514f77d2d-0dbb27f700000123_1150579282_data.0.txt
```