---
title: CDSW Job Failures due to CNI Plugin Network Error (Status 34)
description: Investigation into failed CDSW jobs (e.g., Set_Point_Automation) with engine exit status 34. Root cause traced to CNI plugin issues on node `wrkcdsw4`, resolved by restarting Docker via Cloudera's supervisord. Covers logs, Kubernetes inspection, node-specific recovery, and customer communication.
tags:
  - bigstreamer
  - cdsw
  - status 34
  - engine exited
  - job failure
  - cni plugin
  - weave
  - kubernetes
  - docker restart
  - wrkcdsw4
  - supervisord
  - energy bills
  - set_point_automation
  - cabins_live_measurements
  - monitoring_flows
  - job logs missing
  - root cause analysis
  - cdsw recovery
  - mncdsw1
  - cluster node issue
last_updated: 2025-05-01
author: ilpap
context:
  issue_id: IM1923742
  system: abc BigStreamer CDSW
  root_cause: Weave network plugin unresponsive on node wrkcdsw4
  node: wrkcdsw4.bigdata.abc.gr
  affected_jobs:
    - Set_Point_Automation (Set Point Automation)
    - Cabins Live Measurements (Energy Bills)
    - Flows_update_all_counters_12:00_no_par_dt (Monitoring Flows)
  error_code: Engine exited with status 34
  resolution: Docker restarted via supervisorctl to restore container runtime health
---
# abc - IM1923742 - Job's problem
## Description
it has been observed that jobs show the problem Engine exited with status 34.
some of them are:
• Set_Point_Automation job in the Set Point Automation project (error today 22/7)
• Cabins Live Measurements job in the Energy Bills project (error yesterday 21/7)
• Flows_update_all_counters_12:00_no_par_dt job in the Monitoring Flows project (error yesterday 7/15)
## Actions Taken
### 1. Identify Affected Jobs and Confirm Failure via CDSW UI
1. Connect with you personal ldap account in 'https://mncdsw1.bigdata.abc.gr/'
2. Go to last tab(admin).
3. Select `Activity` tab.
4. Inspect the Jobs in question.
The jobs are in `FAILED` status. The logs for the failed applications are missing.
### 2. Investigate Job Pod Failures in Kubernetes
5. Troubleshoot from the command line:
From `mncdsw1` as root (use personal account and then sudo):
```bash
kubectl get pods -w -A # Wait a pod to fail (namespace should be like default-user-XXX)
# After a while, a pod has failed, describe it
kubectl describe pod -n default-user-XXX XXXXXXXX
```
### 3. Identify Root Cause from CNI/Weave Logs
```logs
Events
Warning  FailedCreatePodSandBox  10s                    kubelet, wrkcdsw4.bigdata.abc.gr  Failed to create pod sandbox: rpc error: code = Unknown desc = [failed to set up sandbox container "..." network for pod "XXXXXXXX": networkPlugin cni failed to set up pod "XXXXXXXX_default" network: unable to allocate IP address: Post http://127.0.0.1:6784/ip/....: dial tcp 127.0.0.1:6784: connect: connection refused, failed to clean up sandbox container "...." network for pod "XXXXXXXX": networkPlugin cni failed to teardown pod "XXXXXXXX_default" network: Delete http://127.0.0.1:6784/ip/....: dial tcp 127.0.0.1:6784: connect: connection refused]
```
This error points us to the CNI plugin
Check the logs for the weave pods:
``` bash
kubectl logs -n kube-system weave-net-XXXXX
# Weave pod in wrkcdsw4 has stopped logging events
```
The pod was not responding and could not be deleted.
### 4. Restore Weave Functionality by Restarting Docker
7. Restart the docker daemon to restart all containers on `wrkcdsw4`
_At the time of the issue, CDSW had stale configuration that required full restart (outage) which was not desirable_
To avoid applying the settings, restart the service with the same configuration by triggering a restart by `supervisord` deployed as part of the Cloudera agent
#### Details
 ![Danger ahead](https://media3.giphy.com/media/vvzMdSygQejBIejeRO/200w.gif?cid=6c09b952aacsm9yssw6k6q0z5v8ejuy82rjpvw6qdhglcwpu&rid=200w.gif&ct=g)
From wrkcdsw4 as root (use personal account and then sudo):
```bash
/opt/cloudera/cm-agent/bin/supervisorctl -c /var/run/cloudera-scm-agent/supervisor/supervisord.conf status | grep DOCKER
# Sample
# 145071-cdsw-CDSW_DOCKER          RUNNING   pid 39353, uptime 29 days, 0:40:20
/opt/cloudera/cm-agent/bin/supervisorctl -c /var/run/cloudera-scm-agent/supervisor/supervisord.conf restart 145071-cdsw-CDSW_DOCKER
```
### 5. Confirm Recovery and Notify Customer
8. Check that the node is operational after the restart
From `mncdsw1` as root (use personal account and then sudo):
```bash
cdsw status # You might have to wait a few minutes
```
9. Inform the customer about the problem
``` text
A component of CDSW on worker node 4 encountered a problem resulting in jobs running on that node not being able to start. The function of the component has been restored and the jobs are now running normally.
## Affected Systems
abc Bigstreamer CDSW