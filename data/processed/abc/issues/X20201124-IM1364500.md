---
title: Hive2Script Job Failure - Corrupt Parquet File in osix.sip Partition
description: Resolution of failed Hive2Script Oozie job in abc BigStreamer due to corrupt Parquet file in osix.sip partition (par_dt=20201123, par_hr=08); includes file inspection, fsck, and table refresh commands.
tags:
  - bigstreamer
  - abc
  - hive2script
  - hive
  - impala
  - spark
  - oozie
  - parquet
  - corrupted-parquet
  - fsck
  - metadata
  - partition-refresh
  - stale-metadata
  - osix
  - osix.sip
  - hdfs
  - application_failure
last_updated: 2025-05-01
author: ilpap
context:
  environment: BigStreamer
  cluster: abc
  issue_id: IM1364500
  table: osix.sip
  affected_partition:
    par_dt: "20201123"
    par_hr: "08"
  error:
    message: File has an invalid version number
    cause: Corrupt Parquet file
  nodes:
    - unosix1.bigdata.abc.gr
    - sn87.bigdata.abc.gr
    - un2.bigdata.abc.gr
  tools:
    - parquet-tools
    - hdfs fsck
    - impala-shell
    - yarn logs
    - hive
    - oozie
    - spark
    - kinit
  corrupt_files:
    - part-00006-17ead666-d5cb-437e-a849-c08ef825bec4.c000
  commands_executed:
    - REFRESH osix.sip PARTITION
    - parquet-tools meta
    - hdfs dfs -mv
---
# abc - BigStreamer - IM1364500 - abc BigStreamer oozie job hive2script failed / stale metadata
## Description
Impala queries finish with error for table osix.sip and partition 20201123
Message:
ERROR processing query/statement. Error Code: 0, SQL state: File 'hdfs://nameservice1/ez/warehouse/osix.db/sip/par_dt=20201123/par_hr=08/par_method=REGISTER/part-00006-17ead666-d5cb-437e-a849-c08ef825bec4.c000' has an invalid version number: .??6
This could be due to stale metadata. Try running "refresh osix.sip".
## Actions Taken
1. Checked that same query results in error using Hive.
2. Checked that the problem occurs only with par_hr=08 partition. 
```bash
select distinct sip.callinguser 
as callinguser 
from OSIX.sip where par_dt='20201123' 
AND par_hr != '08' 
AND sip.callingUser IS NOT NULL;
...
Fetched X rows in X seconds.
```
2. Inspected logs of Osix SIP application for that time. Login in `unosix1.bigdata.abc.gr`, switch user to `osix` and kinit first.
```bash
$ sudo su - osix
$ cd
$ kinit -kt osix.keytab osix
$ yarn logs -applicationId application_1599948124043_405502
```
3. As `sn87.bigdata.abc.gr` was running a Spark executor of this application the time it was forced to shutdown, inspected if there are any corrupt files in the table. Login to any datanode first.
``` bash
$ cd /var/run/cloudera-scm-agent/process/ 
$ ls -lahtr | grep -i hdfs
$ cd <last directory>
$ kinit -kt hdfs.keytab hdfs/`hostname -f`
$ hdfs fsck /ez/warehouse/osix.db/sip/par_dt=20201123/par_hr=08 -includeSnapshots
...
Status healthy
```
4. Inspected format of written files. After communication with the dev team the batch id was retrieved so only a few files were checked. Login to un2.  
```
$ hdfs dfs -copyToLocal /ez/warehouse/osix.db/sip/par_dt=20201123/par_hr=08/part-*-17ead666-d5cb-437e-a849-c08ef825bec4.* .
$ parquet-tools meta part-00006-17ead666-d5cb-437e-a849-c08ef825bec4.c000
file:/home/users/u15/part-00006-17ead666-d5cb-437e-a849-c08ef825bec4.c000 is not a Parquet file. expected magic number at tail [80, 65, 82, 49] but found [46, -19, -49, 54]
```
This confirms the file is corrupted and unreadable by Hive or Impala.
4. Some of the files didn't have a correct parquet format so we removed them from the table.
```bash
$ hdfs dfs -mv hdfs dfs -mv  /ez/warehouse/osix.db/sip/par_dt=20201123/par_hr=08/par_method=OTHER/part-00005-17ead666-d5cb-437e-a849-c08ef825bec4.c000 /ez/landingzone/tmp/osix_sip/other
...
```
### Resolution: Remove corrupt file and refresh Hive metadata
5. Refresh the table and check that problem is fixed.
```
REFRESH osix.sip PARTITION (par_dt='20201123', par_hr='08', par_method='REGISTER');
REFRESH osix.sip PARTITION (par_dt='20201123', par_hr='08', par_method='OTHER');
select count(*) from OSIX.sip where par_dt='20201123' ;
``` 
## Affected Systems
abc Bigstreamer Backend