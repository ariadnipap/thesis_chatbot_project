---
title: HDFS Block Count Alert on dr1node09 Due to service_audit_old Table Fragmentation
description: An HDFS alert was triggered on the Disaster Site due to an excessive number of blocks on dr1node09 caused by unmanaged historical partitions in the prod_trlog_ibank.service_audit_old table. The issue was mitigated by dropping old partitions manually and recommending a retention policy.
tags:
  - bigstreamer
  - hdfs
  - cloudera manager
  - block count
  - dr1node09
  - datanode alert
  - impala
  - service_audit_old
  - retention
  - purge partitions
  - grafana monitoring
  - hive partitioning
  - memory pressure
  - performance issue
  - mno
  - dr site
last_updated: 2025-05-01
author: ilpap
context:
  issue_id: IM1681883
  system: MNO BigStreamer DR Site
  root_cause: Excessive historical data in Hive table caused high block count and memory issues on dr1node09
  user_visible_error: Cloudera Manager HDFS Datanode Data Directory Status alert
  action_taken:
    - Verified datanode imbalance in Namenode UI
    - Identified service_audit_old table as root cause
    - Proposed and executed manual partition purge
    - Coordinated with monitoring and customer teams
  outcome: Alert cleared after dropping old partitions; retention mechanism recommended
---
# mno - BigStreamer - IM1681883 - hdfs issue on cloudera manager
## Description
On October 20th, 2021, an HDFS "Datanode Data Directory Status" alert appeared in Cloudera Manager for dr1node09 on the Disaster Recovery site. Investigation showed that the alert was caused by excessive block count due to the absence of a retention policy for the `prod_trlog_ibank.service_audit_old` table in Hive. Manual purging of old partitions was performed to mitigate the issue.
## Actions Taken
1. Login to Cloudera Manager in DR and check the alarm
2. It was a block count alarm on `dr1node09`
3. Login to `dr1edge01` with your personal account and execute `firefox` to view the Namenode UI.
4. Go to `https://dr1node02.mno.gr:50470` and from there in the tab `Datanodes`. Order the datanodes using the block count by desceding order to overview the situation.
5. Change user to PRODREST and use HDFS command or Impala query to check how many partitions exist in `prod_trlog_ibank.service_audit_old`. This is a big table that has no retention mechanism yet so its data are stored in many blocks. HDFS command is `hdfs dfs -ls /mno_data/hive/warehouse/prod_trlog_ibank.db/service_audit_old` and Impala query is `show partitions prod_trlog_ibank.service_audit_old`. In either case observe how many `par_dt` directories exist.
6. In our case there were at least 6 months in there so we informed mno. Sample customer notification:
```text
Regarding ticket SD1734269, the error shown in Cloudera Manager refers to a block count threshold exceeded on dr1node09 and is due to the increased number of blocks stored on the new nodes dr1node07-10. The impact on the datanode lies in the performance as the metadata for the blocks it has in memory does not fit.
From the investigation we did in the HDFS data, we saw that there are many files in the prod_trlog_ibank.service_audit_old table. Specifically, there is history in it from 01/03.
By keeping only recent data through a retention mechanism, the total block count in HDFS and on each datanode individually will be reduced.
As an immediate solution, we suggest deleting data older than 40 days, as has been done in the past. Consequently, it will not be possible to investigate problems that occurred older than 40 days.
Please let us know if you agree with the above and when you would like us to proceed with the immediate solution.
```
Recipients are `ZEVGAROPOULOU.GEORGIA@mno.gr,krekoukias.konst@mno.gr,papakostas.athanasios@mno.gr`. Add our team and kbikos in CC.
5. When mno agreed to the immediate action, we informed the monitoring team to ignore alarms in Cloudera Manager of DR site regarding HDFS, Hive, Impala and YARN. Their email address is `csocmonitoringops@jkl-telecom.com`. Example mail:
```
We will proceed with actions on the National Bank of Greece Disaster Site infrastructure.
During this time, you will probably have alarms in the Cloudera Manager UI related mainly to the Health of HDFS, Hive, Impala, Yarn.
The work will start at 16:40 today. We will inform you after the work is completed.
```
8. When the time comes, login to Grafana and check charts of topologies running in DR. Login to Cloudera Manager and check throughout the process the health status of Cloudera services. Ndef that `Hive Metastore Canary` alerts will pop up as expected.
9. Login to dr1edge01 with your personal account and change user to `PRODREST`.
10. Open an impala shell on DR:`impala-shell -i pr1edge.mno.gr -k --ssl`.
11. Change database to `prod_trlog_ibank` with `use prod_trlog_ibank;` and `show tables;` to check that `service_audit_old` is here.
12. Drop partitions. Seperate the amount of days you have to delete in batches of 15 days in order to avoid disruptions of applications. `ALTER TABLE service_audit_old DROP IF EXISTS PARTITION(par_dt<=20200715) PURGE;`
12. When the query is done, execute the next one and so on: `ALTER TABLE service_audit_old DROP IF EXISTS PARTITION(par_dt<=20200801) PURGE;`
13. Can't stress this enough. **Throughout steps 12, 13 check Grafana and Cloudera Manager**.
14. When done, inform mno and the monitoring team that actions have been successfully finished.
## Affected Systems
mno Bigstreamer
## Action Points
Develop retention mechanism to automatically drop old partitions.