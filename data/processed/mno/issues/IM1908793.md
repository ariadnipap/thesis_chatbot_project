---
title: HDFS Data Directory Status Alert on dr1node02 Due to Failing Disk
description: Cloudera Manager triggered a Data Directory Status alert on dr1node02 caused by a failing disk; resolved through disk replacement, RAID reconfiguration, and validation using bdadiskutility and MegaCli64.
tags:
  - mno
  - bigstreamer
  - cloudera
  - hdfs
  - datanode
  - disk replacement
  - data directory status
  - dr1node02
  - bdadiskutility
  - megacli
  - raid
  - nfs
  - oracle support
  - dr site
  - disk mirroring
  - sd2389640
last_updated: 2025-05-01
author: ilpap
context:
  issue_id: SD2389640
  system: mno BigStreamer DR Site
  affected_node: dr1node02
  root_cause: Data Directory Status alert caused by failing disk in slots s1 and s7 on dr1node02
  resolution_summary: Disks were replaced online with no downtime using bdadiskutility and MegaCli64 to clear cache, reconfigure RAID, and validate partitions; DataNode role restarted successfully
  maintenance_window_required: false
  impact: No downtime
---
# mno - BigStreamer - IM1908793 - Error on creating kudu table
## Description
An HDFS Data Directory Status alert on dr1node02 was triggered due to a failing disk in slots s1 and s7. The issue was resolved through coordinated disk replacement, cache clearing, and RAID reinitialization using MegaCli64.
Error while creating a temporary kudu table:
```
ERROR: ImpalaRuntimeException: Error creating Kudu table 'prod_trlog_card_analytical.opticash_dispencing_atm_tmp'
CAUSED BY: NonRecoverableException: failed to wait for Hive Metastore notification log listener to catch up: failed to retrieve notification log events: failed to get Hive Metastore next notification: Thrift SASL frame is too long: 338.01M/100.00M
```
## Actions Taken
**Steps in order to investigate and make sure that the table is not created**
1. Login to `dr1edge01.mno.gr` with personal account and then to `dr1node01.mno.gr`
2. Move to the process folder:
```bash
cd /var/run/cloudera-scm-agent/process/
```
3. Find the latest process and go to that folder. In our case is 12200-kudu-KUDU_TSERVER. So move to that folder:
```bash
cd 12200-kudu-KUDU_TSERVER
```
4. Use the keytab you just found in that folder:
```bash
kinit -kt kudu.keytab kudu/`hostname`
```
5. Check kudu cluster health and specifically for `prod_trlog_card_analytical` database in order to check if the wanted table is created.
```bash
kudu cluster ksck dr1node04.mno.gr dr1node05.mno.gr dr1node06.mno.gr | grep -i prod_trlog_card_analytical
```
As you can see the `prod_trlog_card_analytical.opticash_dispencing_atm_tmp` table is not created.
**Optional**: You can also verify that from impala-shell running the following commands:
- Login to `dr1edge01.mno.gr` with personal account
- impala-shell -i dr1edge01 -k --ssl
- `[dr1edge01.mno.gr:21000] default> use prod_trlog_card_analytical;`
- `[dr1edge01.mno.gr:21000] default> show tables;`
As you can see the `prod_trlog_card_analytical.opticash_dispencing_atm_tmp` table is not created.
6. Login to CM DR with your pesonal account > Go to impala > Queries
7. In the search bar type the following in order to find the query:
`STATEMENT RLIKE '.*prod_trlog_card_analytical.opticash_dispencing_atm_tmp'.*` and click on the query details for investigation.
We found that the query they try to run is the following:
```bash
CREATE TABLE IF NOT EXISTS prod_trog_card analytical.opticash ispencing_atm_tmp
cashp id, STRING NOT NULL
, transaction date STRING NOT NULL
,denom id STRING
, cassette STRING
, crncy id STRING
, open Bal BIGINT
, norm del BIGINT
, norm rtr BIGINT
, unpl_ del BIGINT
, unpl_tr BIGINT
, wthdrwls BIGINT
, pre_wdrw BIGINT
, deposits BIGINT
, clos_bal BIGINT
, bal_disp BIGINT
, bal_escr BIGINT
, bal_unav BIGINT
, opr_stat STRING
, excld_fl STRING
â€šPRIMARY KEY (cashp_id, transaction date, denom_id, cassette)
) STORED AS KUDU
```
We try to rerun the above query and we get the following error:
```bash
ERROR: ImpalaRuntimeException: Error creating Kudu table 'prod_trlog_card_analytical.opticash_dispencing_atm_tmp'
CAUSED BY: NonRecoverableException: failed to wait for Hive Metastore notification log listener to catch up: failed to retrieve notification log events: failed to get Hive Metastore next notification: Thrift SASL frame is too long: 338.01M/100.00M
```
### Resolution
As a first step, let's try to fix `Thrift SASL frame is too long: 338.01M/100.00M` error.
1. Login to Cloudera Manager in DR site with your personal administrative account:
`Kudu > Instances > Click on Master > Select Tab Configuration`
2. In `Search` box write safety valvue and at `Master Advanced Configuration Snippet (Safety Valve for gflagfile)` add th following flag:
```bash
--hive_metastore_max_message_size_bytes=858993459
```
>**Important Ndef**:  The above step with flag must be set at all three masters
3. Restart the three kudu masters (one at a time)
4. After rerunning the query the table is not still created but this time we get the following error: 
```bash
SASL decode failed: SASL(-1): generic failure:
wO706 15:44:11.242372 109675 hms_notification_log_listener.cc:130] Hive Metastore notification log listener poll failed: Not authorized: failed to ret
rieve notification log events: failed to get Hive Metastore next notification: SASL decode failed: SASL(-1): generie failure:
w0706 15:44:35.127687 109673 hms_client.cc:345] Time spent get HMS notification events: real 8.885s user 0.000s sys 0.228s
```
5. Restarting all Tablet Servers (dr1node01-10),one at a time, fixed the problem. 
**Before Restarting Tablets the following Flows must be stopped !!!**
```
PROD_IBANK_IngestStream_Visible
PROD_Online_IngestStream
PROD_IBank_IngestStream
```
Stop the flows:
>Ndef: We used following command because flows were working fine. Otherwise, we you should kill the application.
```bash
hdfs dfs -put SHUTDOWN /user/PRODREST/service/PROD_IBank_Ingest/topology_shutdown_marker/
hdfs dfs -put SHUTDOWN /user/PRODREST/service/PROD_IBank_Ingest_Visible/topology_shutdown _marker/
hdfs dfs -put SHUTDOWN /user/PRODREST/service/PROD_Online_Ingest/topology_shutdown_marker/
```
When Tablets are all up and running make sure you start again the flows. 
Verify that Tablets and Kudu is up and running by checking graphs and CM UI (CM -> Kudu -> Charts Library)
Information about how to start flows can be found [here](http://https://metis.ghi.com/obss/oss/sysadmin-group/support/-/tree/master/KnowledgeBase/mno/BigStreamer/supportDocuments/applicationFlows "here")
We verified that the problem is fixed by running the querry and got Table has been created message.
## Root Cause Analysis
This problem occurred due to dr1node07 disk replacement.
Please refer to *IM1893876* for more information.
The fact that kudu tablets were offline for more than 1 days resulted in networking issues between Tablets.
## Affected Systems
Disaster Site