---
title: DWH LoanPayment Export Failed Due to Duplicate Primary Key in SQL Server
description: The `EXPORT` job for the `LOAN_PAYMENT` component in DWH_IBank failed due to duplicate IDs in the staging table, violating SQL Server's primary key constraint during Sqoop export; resolved by reconstructing the partition and keeping only the valid record.
tags:
  - mno
  - bigstreamer
  - dwh_ibank
  - loan_payment
  - export failure
  - duplicate id
  - sqoop
  - sqoop export
  - impala
  - sql server
  - primary key violation
  - dwh_details_loan_payment
  - staging table
  - batch job
  - impala shell
  - yarn
  - grafana
  - im2070630
last_updated: 2025-05-01
author: ilpap
context:
  issue_id: IM2070630
  system: mno BigStreamer DWH
  root_cause: Two records with the same `id` and different timestamps were exported, violating SQL Server's unique constraint during Sqoop export
  resolution_summary: A temporary table was created with deduplicated entries for `par_dt=20230125`, and the target table was overwritten; job was re-executed successfully
  duplicate_id: 0E86AF89-F15C-4B78-8925-08ED8D237805
  conflict_table: prod_trlog_ibank_analytical.dwh_details_loan_payment
  export_script: sched_export_to_dwh.sh -t loanPayment
  export_component: LOAN_PAYMENT
  failure_code: 1
---
# mno - BigStreamer - IM2070630 - Failed batch Job on Grafana
## Description
The `EXPORT` batch job for `DWH_IBank â†’ LOAN_PAYMENT` failed on 26/01/2023 with code `1`, due to a `PRIMARY KEY` violation in the external SQL Server system.
```
Application: DWH_IBank
Job Name: EXPORT
Component: LOAN_PAYMENT
Status: Failed
Description: Code:1
Thanks
```
## Actions Taken
### Root Cause Analysis
Analysis was performed in collaboration with @lmn and @iaravant
1. Check MapReduce logs from YARN UI - App Name: PROD_IBank_DWH_EXPORT_LoanPaymentDetails_*
![IM2070630_yarn_app](.media/IM2070630_yarn_app.png)
![IM2070630_yarn_mapreduce](.media/IM2070630_yarn_mapreduce.png)
There was a duplicate entry in `prod_trlog_ibank_analytical.dwh_details_loan_payment_stg`:
```
Duplicate Key Value: 0E86AF89-F15C-4B78-8925-08ED8D237805
```
2. Check the tables from Impala Shell with PRODUSER
```bash
[PRODUSER@dr1edge01 ~]$ impala-shell -k -i dr1edge.mno.gr --ssl
```
Check for duplicates in dwh_details_loan_payment_stg and dwh_details_loan_payment with id=0E86AF89-F15C-4B78-8925-08ED8D237805
![IM2070630_details_duplicates](.media/IM2070630_details_duplicates.PNG)
Check service_audit specifically for id=0E86AF89-F15C-4B78-8925-08ED8D237805
![IM2070630_service_audit](.media/IM2070630_service_audit.PNG)
Check service_audit for duplicates
![IM2070630_service_audit_monthly](.media/IM2070630_service_audit_monthly.PNG)
Service_audit contained two entries with the same id=0E86AF89-F15C-4B78-8925-08ED8D237805 and different timestamps.
### Resolution
Solution provided by @fgh and @adrint
```bash
[PRODUSER@dr1edge01 ~]$ impala-shell -k -i dr1edge.mno.gr --ssl
```
```sql
--- == DWH LoanPayment ==
 --Create table with original data
create table prod_trlog_ibank_analytical.20230126_dwh_details_loan_payment_orig like prod_trlog_ibank_analytical.dwh_details_loan_payment;
insert into prod_trlog_ibank_analytical.20230126_dwh_details_loan_payment_orig partition(par_dt) select * from prod_trlog_ibank_analytical.dwh_details_loan_payment where par_dt=20230125;
-- Create table and insert only required data
create table prod_trlog_ibank_analytical.20230126_dwh_details_loan_payment_tmp like prod_trlog_ibank_analytical.dwh_details_loan_payment;
insert into prod_trlog_ibank_analytical.20230126_dwh_details_loan_payment_tmp partition(par_dt) select * from prod_trlog_ibank_analytical.dwh_details_loan_payment where par_dt = 20230125 and id != '0E86AF89-F15C-4B78-8925-08ED8D237805';
insert into prod_trlog_ibank_analytical.20230126_dwh_details_loan_payment_tmp partition(par_dt) select * from prod_trlog_ibank_analytical.dwh_details_loan_payment where par_dt = 20230125 and id = '0E86AF89-F15C-4B78-8925-08ED8D237805' and tr_timestamp = '202301025 09:38:13.072489000' limit 1;
-- Overwrite normal table with correct data
insert overwrite prod_trlog_ibank_analytical.dwh_details_loan_payment partition(par_dt) select * from prod_trlog_ibank_analytical.20230126_dwh_details_loan_payment_tmp where par_dt = 20230125;
```
```bash
# Run Export procedure 
/opt/ingestion/PRODUSER/datawarehouse-ibank/export_to_dwh/sched_export_to_dwh.sh -t loanPayment
```
```bash
[PRODUSER@dr1edge01 ~]$ impala-shell -k -i dr1edge.mno.gr --ssl
```
```bash
# Drop temporary table
drop prod_trlog_ibank_analytical.20230126_dwh_details_loan_payment_tmp purge
# TODO Check data and drop backup table with initial orginal data
drop prod_trlog_ibank_analytical.20230126_dwh_details_loan_payment_orig purge
```
## Our Ticket Response
```text
After investigation, it was determined that there is a problem with two different transactions that occurred on 25/01/2023 which were declared with the same id.
The external SQL server LoanPaymentDetails restricts the id field to be UNIQUE, hence the expected error displayed by sqoop-export.
SQLException: Violation of PRIMARY KEY constraint 'PK_LoanPaymentDetails'.
Cannot insert duplicate key in object 'srcib.LoanPaymentDetails'.
The duplicate key value is (0e86af89-f15c-4b78-8925-08ed8d237805)
The id of the problematic transaction is 0E86AF89-F15C-4B78-8925-08ED8D237805 and the first transaction has a timestamp of 09:38:13.072489000 while the second one has a timestamp of 2023-01-25 2023-01-25 09:38:13.476066000.
We suggest deleting one of the two transactions so that we can proceed with the export of the loan payment data for the remaining transactions. The information for both transactions remains in the big data environment
so it can be retrieved if needed later.
```
```text
After communication via email, we proceeded to reconstruct the table, keeping only the record with timestamp 09:38:13.072489000 and reran the job. Please, investigate this on your part and take the necessary actions so that duplicate records are not sent to us.
```