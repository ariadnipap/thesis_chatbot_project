---
title: IBank MergeBatch Job Failed Due to HBase Quotas and Impala Resource Exhaustion
description: The MergeBatch job for IBank_Ingestion failed due to Impala daemon resource exhaustion triggered by HBase namespace quotas and large data volume; workaround involved disabling quotas and rerunning in distributed mode.
tags:
  - mno
  - bigstreamer
  - ibank
  - mergebatch
  - batch job
  - impala
  - hbase
  - quotas
  - pr1node04
  - spark
  - yarn
  - resource exhaustion
  - visible table
  - service audit
  - impala daemon
  - impala concurrency
  - code 6
  - IM2095966
  - impala parallelism
  - spark-submit
  - job retry
  - prodrest
last_updated: 2025-05-01
author: ilpap
context:
  issue_id: IM2095966
  system: mno BigStreamer PR Site
  root_cause: HBase write quotas limited Impala to a single daemon, which crashed under end-of-month load, causing Impala connection pool exhaustion and failure of the MergeBatch job
  resolution_summary: MergeBatch was rerun in 3 time windows after disabling quotas in the PROD_IBANK namespace to allow full Impala daemon usage
  workaround: quota removal and distributed rerun
  affected_nodes:
    - pr1node04
    - pr1edge01
  impacted_component: IBank_Ingestion MergeBatch (Spark + Impala + HBase)
  customer_impact: night flows disrupted, visible table update delayed
---
# mno - BigStreamer - IM2095966 - Failed Batch Job on Grafana
## Description
The MergeBatch job for the IBank_Ingestion pipeline failed on 28/02/2023 on the PR Site with a Grafana alert. The failure occurred during the `JOB` component execution and was traced to Impala resource exhaustion caused by HBase write quotas and high data volume at end-of-month.
The following failed batch job appeared in the Grafana system:
```
application :  IBank_Ingestion
job_name : MergeBatch
component : JOB
date : 28-02-2023
status : FAILED
description :
host : pr1edge01.mno.gr
```
## Actions Taken
1. We identified the failed step using the alarm name. Steps `MSSQL Sqoop Import (Migration)` and `Insert to Service Audit` had been executed successfully. We rerun the `Merge Batch` according to [this](../supportDocuments/applicationFlows/ibank.md#merge-batch).
2. The job had not completed at approximately 9.pm on 01/03/2023 we terminated the job after communication with the customer in order for the night flow to run without any problems. We scheduled to rerun the job in the following day after the completion of the daily MergeBatch.
3. On 02/03/2023 we reran the job in 3 patches 
```bash
/opt/ingestion/PRODREST/ibank/spark/submit/submitmnoSparkTopology_batch_cluster_mno_STABLE.sh "2023-02-28 00:00:00" "2023-02-28 12:00:00"
/opt/ingestion/PRODREST/ibank/spark/submit/submitmnoSparkTopology_batch_cluster_mno_STABLE.sh "2023-02-28 12:00:00" "2023-02-28 18:00:00"
/opt/ingestion/PRODREST/ibank/spark/submit/submitmnoSparkTopology_batch_cluster_mno_STABLE.sh "2023-02-28 18:00:00" "2023-03-01 00:00:00"
```
4. The `Upsert to HBase` stage that synchronises the `Visible` table caused an Impala problem during which Impala stopped to process this job as well as other requests.
5. The problem is described below.
## Our Ticket Response
```
03/03/23 11:17:49 Europe/Eastern (POULAS GIORGOS):
After investigating yesterday's Impala issue, we found the following:
Due to HBase quotas set in the PROD_IBANK namespace, we have limited the parallelism in the Impala query to run on an Impala daemon.
The daemon that ran the query to enrich the Service Audit Visible (pr1node04) encountered a problem as it did not have the resources required to process the large volume of records we had at the end of the month, while at the same time accepting requests from the REST APIs of the live streams.
As a result of the above, the queries from the live systems were not completing and accumulating, exhausting the available connections that Impala can accept. The malfunction of the live streams is also the problem you observed last night.
We propose as a workaround today after 9pm. disable quotas in the PROD_IBANK namespace and rerun the script without the single node limitation, so that the load is shared across all 9 available Impala daemons. We will then examine the alternatives for modifying the flow and re-enabling quotas.
There is no downtime required for the above actions.
G. Poulas
03/03/23 00:53:26 Europe/Eastern (MASTROKOSTA MARIA):
The service audit has been filled on the PR Site. The job that fills the visible table is pending as it was canceled in the context of ticket SD2159021.
02/03/23 15:56:38 Europe/Eastern (MASTROKOSTA MARIA):
The execution on both sites started after the scheduled execution of the Merge Batch for 01/03/2023, which has been completed without a problem. At this time, the DR has processed until 18:00, while the PR has processed the data until 12:00. The executions on both sites are being monitored so that they can be resubmitted in case of a problem.
01/03/23 21:11:19 Europe/Eastern (MASTROKOSTA MARIA):
Following our telephone communication, the job has been stopped and will be re-executed tomorrow in order to avoid problems with the evening streams.
```