---
title: DWH_IBank EXPORT Job Failure Due to Compute Stats Resource Contention
description: EXPORT job for component CARD failed with Code 6 due to Impala resource saturation caused by COMPUTE STATS on large table `prod_trlog_ibank.service_audit`, which blocked metadata operations and caused extract script timeouts.
tags:
  - mno
  - bigstreamer
  - dwh_ibank
  - card export
  - compute stats
  - impala
  - query timeout
  - code 6
  - resource pool
  - disaster recovery
  - service_audit
  - export failure
  - grafana alert
  - cloudera manager
  - metadata refresh
  - monitoring dashboard
  - impala insert
  - sqoop export
  - job recovery
  - im2024442
last_updated: 2025-05-01
author: ilpap
context:
  issue_id: IM2024442
  system: mno BigStreamer DWH Disaster Recovery Site
  root_cause: EXPORT job timed out because Impala was saturated by a COMPUTE STATS operation on the service_audit table, which blocked subsequent metadata and extract queries
  resolution_summary: The compute stats query completed and resources were released; workaround was to rerun job and disable stats generation for the problematic table
  blocking_query: COMPUTE STATS prod_trlog_ibank.service_audit
  affected_job: DWH_IBank EXPORT CARD
  job_status_code: 6
---
# mno - BigStreamer - IM2024442 - Failed job at Grafana
## Description
On 26/10/2022, the DWH_IBank EXPORT job for component `CARD` failed with status code 6, indicating a timeout in the control script while waiting for the `EXTRACT` phase to finish.
```bash
Application: DWH_IBank
Job Name: EXPORT
Component: CARD
Date: 26/10/2022
Status: FAILED
Description: Code:6
```
## Actions Taken
1. Login to `https://dr1edge01.mno.gr:3000` with personal account and confirm that Datawarehouse Flows have failed from `Monitoring/Monitoring PR/DR` dashboard.
2. All flows have failed with `Code: 6` which means that the control script has timed-out while monitoring the `EXTRACT` script. The `EXTRACT` step has 2 sub-steps: `Impala Insert` and `Sqoop Export`.
3. Check logs:
From `dr1edge01.mno.gr` with personal account:
``` bash
less /var/log/datawarehouse-ibank/PRODUSER/sched_extract.log
```
In this file for all flows that failed we see that the last log entry is the submission of the `Impala Insert` part of the `EXTRACT`, which was still running. This means that another query is hogging all resources for Impala and our flows are waiting to be executed.
4. Login to Disaster Site Cloudera Manager `https://dr1edge01.mno.mno.gr:7183` and check for resource intensive Impala queries `Clusters > Impala > Queries`. The key resource here is memory as this is the only metric that can be defined in Resource Pools.
The query that created the problem was `COMPUTE STATS prod_trlog_ibank.service_audit`. Pictures are not included because Impala does not report statistics for the `COMPUTE STATS` queries, but given the size of the table and the time of execution it matched. This hypothesis was later confirmed when the same problem appeared on a later `COMPUTE STATS` execution.
5. We informed the customer to re-run the failed jobs and proposed to stop computing statistics for that table as they did not impact our application.
``` text
27/10/22 13:16:01 Europe/Eastern (POULAS GIORGOS):
Please rerun the flow steps that encountered a problem.
We are continuing to investigate the root cause of the problem.
**Workaround**
27/10/22 13:32:44 Europe/Eastern (POULAS GIORGOS):
Following the previous answer, the compute statistics on the prod_trlog_ibank.service_audit table committed many resources on the Calatog Server and the query Coordinator (dr1node02), resulting in REFRESH/INVALIDATE METADATA operations experiencing long execution times and causing jobs to time out. After the compute statistics were completed, Impala released the resources and resumed.
As we have communicated in the past, from our perspective the statistics of the table are not necessary. Please let us know if we can disable the production of statistics for this particular table.
**Resolved**
```
6. The changes for the statistics were implemented as part of [this ticket](obss/oss/sysadmin-group/mno/cloudera-cluster#180).
Disaster Recovery Site Datawarehouse