---
title: Impala Connection Pool Exhaustion During HBase Upsert Job Due to Serial Execution on Coordinator
description: The Impala daemon (pr1node04) was overloaded during execution of the Upsert to HBase stage for the IBANK Visible table due to forced single-node execution, resulting in blocked queries, high concurrent connections, and system health alerts; resolved by reverting script changes and disabling HBase quotas.
tags:
  - mno
  - bigstreamer
  - impala
  - impala daemon
  - impala client connections
  - impala coordinator
  - hbase
  - hbase quotas
  - upsert to hbase
  - ibank visible
  - prodrest
  - spark
  - concurrency
  - impala query failure
  - cloudera manager
  - pr1node04
  - pr1node01
  - resource bottleneck
  - impala query logs
  - impala role restart
  - IM2097021
last_updated: 2025-05-01
author: ilpap
context:
  issue_id: IM2097021
  system: mno BigStreamer PR Site
  root_cause: Forced single-node execution of an Impala upsert query exhausted coordinator (pr1node04), blocking concurrent queries and triggering health alerts
  resolution_summary: Cancelled the long-running query, restarted Impala daemons, removed serial execution flag, and reran the job with parallel execution enabled
  affected_daemons:
    - pr1node01
    - pr1node04
  related_jobs:
    - /opt/ingestion/PRODREST/common/scripts/ibank_visible_trn_hbase_daily_upsert_STABLE.sh
  customer_impact: live stream ingestion and production queries were stalled
---
# mno - BigStreamer - IM2097021 - Multiple Health issues on PR Impala
## Description
On 02/03/2023 at 23:30, multiple Impala daemons across PR Site triggered health alerts in Cloudera Manager due to high concurrent client connections and pause duration warnings. The issue originated from a long-running query used in the IBANK Visible table upsert job, which was executed in single-node mode (via `set num_nodes = 1`). This forced the query to overload the coordinator daemon (pr1node04), which caused query blocking, client connection accumulation, and stalled streaming services.
Today 02/03/2023 & 23:30 the Following alarms appeared on Cloudera:
```
[Impala: Daemon (pr1node01)]
[Impala Concurrent Client Connections]
------------
[Impala: Daemon (pr1node02)]
[Impala Concurrent Client Connections]
------------
[Impala: Daemon (pr1node03)]
[Impala Concurrent Client Connections]
------------
[Impala: Daemon (pr1node04)]
[Pause Duration]
[Impala Concurrent Client Connections]
------------
[Impala: Daemon (pr1node05)]
[Impala Concurrent Client Connections]
------------
[Impala: Daemon (pr1node06)]
[Impala Concurrent Client Connections]
```
## Actions Taken
### Investigation
1. Login to Cloudera for PR Site 
2. To identify the Impala query from `Upsert to HBase` we can see logs from the script at `/var/log/ingestion/PRODREST/ibank/log/ibank_visible_trn_hbase_daily_upsert.log` as `PRODREST` user. We cite a screenshot that shows the query. Also, we see the url where we can monitor the query progress (paste this url on a firefox opened through terminal), as well as the coordinator.
![logs_screenshot](.media/upsert_to_hbase_logs_query.PNG)
> Ndef: These are not logs from that specific script execution, just a sample to see where you can find the query information you need.
3. From `Cloudera > Impala > Queries` we identified the query and noticed that it had stopped getting processed. In addition, we noticed that Impala had stopped processing other queries as well.
### Mitigation
4. We cancelled the query that ran for `/opt/ingestion/PRODREST/common/scripts/ibank_visible_trn_hbase_daily_upsert_STABLE.sh` execution. We can cancel the query in two ways.
1st way: From `Cloudera > Impala > Queries` you can click `cancel` at the dropdown next to the query
2nd way: From the url that we monitor the query.
5. We restarted Impala daemon role for pr1node01. This solved the problem with this specific node, however the service did not correspond.
### Resolution
6. We restarted Impala daemon role for pr1node04 that was the coordinator for the query. This solved the problem and recovered the service functionality.
7. Upon investigation, we concluded that the change to `/opt/ingestion/PRODREST/common/scripts/ibank_visible_trn_hbase_daily_upsert_STABLE.sh` that stops the parallel execution of the query by Impala daemons (set num_nodes = 1) was the cause of the problem.
8. We scheduled to rerun the `Upsert to HBase` stage the following day after reverting the script to use all Impala daemons for parallel execution.
### Long-Term Fix
9.  On 03/03/2023 
- we disabled HBase quotas for ` PROD_IBANK` namespace on PR Site according to [this](https://metis.ghi.com/obss/oss/sysadmin-group/mno/cloudera-cluster/-/blob/master/Documentation/MOP/22263_mno_HBASE_TUNING.docx) MoP
- we removed `set num_nodes = 1` from `/opt/ingestion/PRODREST/common/scripts/ibank_visible_trn_hbase_daily_upsert_STABLE.sh`
- reran the script
10. The script ran successfully
## Action Points
1. We opened [this](https://metis.ghi.com/obss/bigdata/mno/devops-mno/-/issues/67) issue to investigate and deploy a permanent fix for running `/opt/ingestion/PRODREST/common/scripts/ibank_visible_trn_hbase_daily_upsert_STABLE.sh` alongside HBase quotas.
## Our Ticket Response
```
03/03/23 00:49:29 Europe/Eastern (MASTROKOSTA MARIA):
The root cause is the same as ticket SD2158913. The job that populates the visible table was canceled after consultation with the customer as it was affecting the live streams.
The job will be scheduled to be rerun after consultation.
```