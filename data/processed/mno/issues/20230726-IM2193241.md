---
title: Online MergeBatch Failure Due to Kudu Timeout and Excessive Partition Count
description: The Online_Ingestion MergeBatch job failed due to a Kudu timeout caused by excessive partitions (468 instead of 180) on the prod_trlog_online.service_audit_stream table; resolved after partition correction and re-execution.
tags:
  - mno
  - bigstreamer
  - grafana
  - online ingestion
  - mergebatch
  - kudu
  - spark
  - spark ui
  - spark partitions
  - timeout
  - stage 0
  - org.apache.kudu.client.NonRecoverableException
  - prod_trlog_online.service_audit_stream
  - impala partitioning
  - pr1edge01
  - im2193241
last_updated: 2025-05-01
author: ilpap
context:
  issue_id: IM2193241
  system: mno BigStreamer PR Site
  root_cause: MergeBatch Spark job failed due to high partition count (468) and Kudu timeout on service_audit_stream
  resolution_summary: Re-executed flow after reducing table partitions to expected count (180); resolved without job failures
  affected_table: prod_trlog_online.service_audit_stream
  affected_node: pr1edge01.mno.gr
  fix_applied_by: development team
---
# mno - BigStreamer - IM2193241 - Failed job in Grafana
## Description
The MergeBatch job in Online_Ingestion failed due to a `Kudu NonRecoverableException`, caused by an unexpectedly high number of partitions (468 instead of 180) in the Spark job. The development team corrected the partitioning in `prod_trlog_online.service_audit_stream`, and the job succeeded on re-execution.
The following failed job appeared in Grafana today 26/07:
```
Application: Online_Ingestion
Job_name: MergeBatch
Componment: JOB
Date: 25-07-2023
Host: pr1edge01.mno.gr
```
## Actions Taken
The job failed with a timeout while querying Kudu due to an abnormally high number of partitions in Stage 0 of the Spark job.
1. Re-run the failed step as described [here](../supportDocuments/applicationFlows/online.md#batch)
2. The flow completed successfully, we proceeded with the investigation
Logs from the application:
```
Caused by: org.apache.kudu.client.NonRecoverableException: cannot complete before timeout: ScanRequest(scannerId="22c757bfcf674a05a08f14c316e745e9", tablet=c42b07f18435403297fee37add478c0b, attempt=1, KuduRpc(method=Scan, tablet=c42b07f18435403297fee37add478c0b, attempt=1, TimeoutTracker(timeout=30000, elapsed=30004), Trace Summary(0 ms): Sent(1), Received(0), Delayed(0), MasterRefresh(0), AuthRefresh(0), Truncated: false 
```
Spark UI:
![Spark UI](.media/IM2193241_1.png)
3. Stage 0 should have 180 partitions not 468
![Spark UI normal](.media/IM2193241_2.png)
4. Informed development team to correct the number of partitions for `prod_trlog_online.service_audit_stream`. This deleted unnecessary data from Kudu's disks and next run (see 3) did not have any failed tasks.
## Affected Systems
mno Primary Site